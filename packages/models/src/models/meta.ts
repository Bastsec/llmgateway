import type { ModelDefinition } from "@/models.js";

export const metaModels = [
	{
		id: "llama-3.1-8b-instruct",
		name: "Llama 3.1 8B Instruct",
		family: "meta",
		providers: [
			{
				providerId: "aws-bedrock",
				modelName: "meta.llama3-1-8b-instruct-v1:0",
				inputPrice: 0.22 / 1e6,
				outputPrice: 0.22 / 1e6,
				requestPrice: 0,
				contextSize: 128000,
				maxOutput: 2048,
				streaming: true,
				vision: false,
				tools: false,
				jsonOutput: false,
			},
			{
				providerId: "nebius",
				modelName: "meta-llama/Meta-Llama-3.1-8B-Instruct",
				inputPrice: 0.02 / 1e6,
				outputPrice: 0.06 / 1e6,
				requestPrice: 0,
				contextSize: 128000,
				maxOutput: undefined,
				streaming: true,
				vision: false,
				tools: false,
				jsonOutput: false,
			},
			{
				providerId: "inference.net",
				modelName: "meta-llama/llama-3.1-8b-instruct/fp-8",
				inputPrice: 0.07 / 1e6,
				outputPrice: 0.33 / 1e6,
				requestPrice: 0,
				contextSize: 128000,
				maxOutput: undefined,
				streaming: true,
				vision: false,
				tools: false,
				jsonOutput: false,
			},
			{
				providerId: "together.ai",
				modelName: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
				inputPrice: 0.06 / 1e6,
				outputPrice: 0.06 / 1e6,
				requestPrice: 0,
				contextSize: 128000,
				maxOutput: undefined,
				streaming: true,
				vision: false,
				tools: true,
				jsonOutput: false,
			},
		],
	},
	{
		id: "llama-3.1-70b-instruct",
		name: "Llama 3.1 70B Instruct",
		family: "meta",
		providers: [
			{
				providerId: "aws-bedrock",
				modelName: "meta.llama3-1-70b-instruct-v1:0",
				inputPrice: 0.72 / 1e6,
				outputPrice: 0.72 / 1e6,
				requestPrice: 0,
				contextSize: 128000,
				maxOutput: 2048,
				streaming: true,
				vision: false,
				tools: false,
				jsonOutput: false,
			},
		],
	},
	{
		id: "llama-3.2-11b-instruct",
		name: "Llama 3.2 11B Instruct",
		family: "meta",
		providers: [
			{
				providerId: "inference.net",
				modelName: "meta-llama/llama-3.2-11b-instruct/fp-16",
				inputPrice: 0.07 / 1e6,
				outputPrice: 0.33 / 1e6,
				requestPrice: 0,
				contextSize: 128000,
				maxOutput: undefined,
				streaming: true,
				vision: false,
				tools: false,
				jsonOutput: true,
			},
		],
	},
	{
		id: "llama-3.1-nemotron-ultra-253b",
		name: "Llama 3.1 Nemotron Ultra 253B",
		family: "meta",
		providers: [
			{
				providerId: "nebius",
				modelName: "nvidia/Llama-3_1-Nemotron-Ultra-253B-v1",
				inputPrice: 0.6 / 1e6,
				outputPrice: 1.8 / 1e6,
				requestPrice: 0,
				contextSize: 128000,
				maxOutput: undefined,
				streaming: true,
				vision: false,
				tools: false,
				jsonOutput: true,
			},
		],
	},
	{
		id: "llama-guard-4-12b",
		name: "Llama Guard 4 12B",
		family: "meta",
		providers: [
			{
				providerId: "groq",
				modelName: "meta-llama/llama-guard-4-12b",
				inputPrice: 0.2 / 1e6,
				outputPrice: 0.2 / 1e6,
				requestPrice: 0,
				contextSize: 131072,
				maxOutput: undefined,
				streaming: true,
				vision: false,
				tools: false,
				jsonOutput: false,
			},
		],
	},
	{
		id: "llama-3.3-70b-instruct",
		name: "Llama 3.3 70B Instruct",
		family: "meta",
		providers: [
			{
				providerId: "nebius",
				modelName: "meta-llama/Llama-3.3-70B-Instruct",
				inputPrice: 0.13 / 1e6,
				outputPrice: 0.4 / 1e6,
				requestPrice: 0,
				contextSize: 128000,
				maxOutput: undefined,
				streaming: true,
				vision: false,
				tools: true,
				jsonOutput: true,
			},
		],
	},
	{
		id: "llama-3.1-405b-instruct",
		name: "Llama 3.1 405B Instruct",
		family: "meta",
		providers: [
			{
				providerId: "nebius",
				modelName: "meta-llama/Meta-Llama-3.1-405B-Instruct",
				inputPrice: 1.0 / 1e6,
				outputPrice: 3.0 / 1e6,
				requestPrice: 0,
				contextSize: 128000,
				maxOutput: undefined,
				streaming: true,
				vision: false,
				tools: true,
				jsonOutput: true,
			},
		],
	},
	// {
	// 	id: "llama-guard-3-8b",
	// 	name: "Llama Guard 3 8B",
	// 	family: "meta",
	// 	deprecatedAt: undefined,
	// 	deactivatedAt: undefined,
	// 	providers: [
	// 		{
	// 			providerId: "nebius",
	// 			test: "only",
	// 			modelName: "meta-llama/Llama-Guard-3-8B",
	// 			inputPrice: 0.02 / 1e6,
	// 			outputPrice: 0.06 / 1e6,
	// 			requestPrice: 0,
	// 			contextSize: 8192,
	// 			maxOutput: undefined,
	// 			streaming: true,
	// 			vision: false,
	// 			tools: false,
	// 		},
	// 	],
	// 	jsonOutput: false,
	// },
	{
		id: "llama-4-scout",
		name: "Llama 4 Scout",
		family: "meta",
		providers: [
			{
				providerId: "together.ai",
				modelName: "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
				inputPrice: 0.18 / 1e6,
				outputPrice: 0.59 / 1e6,
				requestPrice: 0,
				contextSize: 32768,
				maxOutput: undefined,
				streaming: true,
				vision: false,
				tools: true,
				jsonOutput: false,
			},
		],
	},
	{
		id: "llama-4-scout-17b-instruct",
		name: "Llama 4 Scout 17B Instruct",
		family: "meta",
		providers: [
			{
				stability: "unstable",
				providerId: "aws-bedrock",
				modelName: "meta.llama4-scout-17b-instruct-v1:0",
				inputPrice: 0.17 / 1e6,
				outputPrice: 0.66 / 1e6,
				requestPrice: 0,
				contextSize: 8192,
				maxOutput: 2048,
				streaming: true,
				reasoningOutput: "omit",
				vision: true,
				tools: false,
				jsonOutput: false,
			},
		],
	},
	{
		id: "llama-4-maverick-17b-instruct",
		name: "Llama 4 Maverick 17B Instruct",
		family: "meta",
		providers: [
			{
				stability: "unstable",
				providerId: "aws-bedrock",
				modelName: "meta.llama4-maverick-17b-instruct-v1:0",
				inputPrice: 0.24 / 1e6,
				outputPrice: 0.97 / 1e6,
				requestPrice: 0,
				contextSize: 8192,
				maxOutput: 2048,
				streaming: true,
				reasoningOutput: "omit",
				vision: true,
				tools: false,
				jsonOutput: false,
			},
		],
	},
] as const satisfies ModelDefinition[];
